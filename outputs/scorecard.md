# PH Top 5 Pre-Launch Readiness Scorecard

Use this scorecard before you pick a launch date. Select one answer per question, total your raw points by category, then convert to the weighted launch-to-revenue score and tier guidance at the end.

## Category 1: Audience Infrastructure (Raw Max 25 | Weighted Max 25)

### Q1. What is your launch list size and 30-day average open rate right now?

**Category**: Audience Infrastructure
**Points Available**: 4

| Option | Answer | Points |
|--------|--------|--------|
| A | 1,000+ subscribers and 40%+ average open rate across last 3 sends | 4 |
| B | 500-999 subscribers and 30-39% average open rate across last 3 sends | 3 |
| C | 100-499 subscribers and 20-29% average open rate across last 3 sends | 2 |
| D | Fewer than 100 subscribers or open rate below 20%, or no baseline data | 0 |

**Why This Matters**: Launch-day traffic quality is often set by list quality, not just list size. High-scoring launches can create comment momentum early, while low-scoring launches depend on cold discovery and usually stall.

<!-- SCORING RATIONALE: This is a 4-point question because owned audience quality drives first-wave engagement and strongly shapes ranking trajectory. -->

### Q2. How many Product Hunt Ship followers do you currently have for this launch?

**Category**: Audience Infrastructure
**Points Available**: 4

| Option | Answer | Points |
|--------|--------|--------|
| A | 250+ Ship followers on the exact product launching | 4 |
| B | 120-249 Ship followers on the exact product launching | 3 |
| C | 40-119 Ship followers on the exact product launching | 2 |
| D | Fewer than 40 Ship followers or no Ship page | 0 |

**Why This Matters**: Ship followers convert into early launch awareness with far less friction than net-new outreach. A low score means you start with weaker intent signals and slower ranking acceleration.

<!-- SCORING RATIONALE: Weighted at 4 because Ship followers are a direct pre-launch momentum asset tied to Product Hunt behavior. -->

### Q3. How many people in your social audience consistently engage with product posts?

**Category**: Audience Infrastructure
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 150+ people routinely like, reply, or repost within 24 hours of product updates | 3 |
| B | 75-149 people routinely engage within 24 hours | 2 |
| C | 25-74 people routinely engage within 24 hours | 1 |
| D | Fewer than 25 routine engagers or inconsistent posting history | 0 |

**Why This Matters**: Raw follower counts can be inflated; engaged reach is what drives first-hour traffic and discussion. Lower engagement depth usually means weaker lift from launch-day social posts.

### Q4. How many people have explicitly committed to comment or engage in the first hour?

**Category**: Audience Infrastructure
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 30+ named people confirmed in writing (DM/email) | 3 |
| B | 15-29 named people confirmed in writing | 2 |
| C | 5-14 named people confirmed in writing | 1 |
| D | Fewer than 5 confirmations or only verbal assumptions | 0 |

**Why This Matters**: The first-hour engagement curve influences visibility for the rest of the day. Clear commitments reduce the risk of a flat opening window.

### Q5. How active have you been in Product Hunt discussions during the last 30 days?

**Category**: Audience Infrastructure
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 20+ meaningful comments on other launches, with replies from founders | 3 |
| B | 10-19 meaningful comments on other launches | 2 |
| C | 3-9 meaningful comments on other launches | 1 |
| D | 0-2 comments or last activity older than 30 days | 0 |

**Why This Matters**: Active community participation raises familiarity and increases thoughtful responses on your own launch. Low activity often leads to a colder reception and thinner comment threads.

### Q6. What launch-intent signal have you measured from your email audience?

**Category**: Audience Infrastructure
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Ran a launch-interest email and got 100+ clicks or 20%+ click rate | 3 |
| B | Ran a launch-interest email and got 50-99 clicks or 12-19% click rate | 2 |
| C | Ran a launch-interest email and got 15-49 clicks or 5-11% click rate | 1 |
| D | No launch-interest email sent or no tracked click data | 0 |

**Why This Matters**: Measured intent beats assumptions about support. Without this signal, you may overestimate who will show up on launch day.

### Q7. How much pre-launch waitlist-to-activation testing have you completed?

**Category**: Audience Infrastructure
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Tested with 50+ users and measured at least 35% activation to core action | 3 |
| B | Tested with 20-49 users and measured at least 25% activation | 2 |
| C | Tested with 5-19 users and measured at least 15% activation | 1 |
| D | Fewer than 5 test users or no measured activation funnel | 0 |

**Why This Matters**: Audience volume helps only if users can reach value quickly after clicking through. Weak activation lowers conversion value from launch traffic.

### Q8. How many third-party amplifiers can credibly share your launch in the first 6 hours?

**Category**: Audience Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | 8+ relevant creators, partners, or community leads confirmed to share | 2 |
| B | 4-7 relevant amplifiers confirmed to share | 1 |
| C | 1-3 amplifiers loosely aware but not confirmed | 0 |
| D | No external amplifiers identified | 0 |

**Why This Matters**: Distributed visibility reduces dependence on one channel and cushions ranking dips. No amplifier plan makes your launch fragile to timing noise.

## Category 2: Asset Quality (Raw Max 20 | Weighted Max 20)

### Q9. Does your thumbnail meet animation and file-size constraints while remaining legible?

**Category**: Asset Quality
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Animated thumbnail under 3MB; tested legibility at 40x40 and 80x80 | 3 |
| B | Animated thumbnail under 3MB; tested only at one reduced size | 2 |
| C | Static thumbnail with strong contrast and tested legibility | 1 |
| D | Oversized, low-contrast, or untested thumbnail | 0 |

**Why This Matters**: Thumbnail clarity affects click-through from crowded feeds. Poor visual clarity suppresses traffic before users even read your copy.

### Q10. Does your tagline pass a 5-second comprehension test with target users?

**Category**: Asset Quality
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 10+ target users tested; at least 8 can explain product value in one sentence | 3 |
| B | 5-9 target users tested; at least 70% can explain value | 2 |
| C | 3-4 users tested or mixed understanding below 70% | 1 |
| D | No comprehension test completed | 0 |

**Why This Matters**: If users cannot quickly restate what you do, they rarely click through or comment. Clear taglines lift both visits and conversion quality.

### Q11. Does Gallery Image 1 communicate the product without needing text?

**Category**: Asset Quality
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 8+ testers can identify user type and core outcome from image alone | 3 |
| B | 5-7 testers can identify user type and outcome from image alone | 2 |
| C | 3-4 testers can identify only one of the two (user type or outcome) | 1 |
| D | Testers need captions to understand what the product does | 0 |

**Why This Matters**: Image 1 functions as your visual pitch in browsing mode. Confusing first visuals reduce downstream engagement regardless of feature depth.

### Q12. Does your demo video show the core "aha" moment within 15 seconds?

**Category**: Asset Quality
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Aha moment appears by second 15; full video is under 90 seconds and captioned | 3 |
| B | Aha moment appears by second 20; full video is under 120 seconds | 2 |
| C | Aha moment appears after second 20 or video exceeds 120 seconds | 1 |
| D | No demo video or no clear aha moment | 0 |

**Why This Matters**: Early proof of value increases watch completion and intent. Delayed payoff causes drop-off before users understand the benefit.

### Q13. Is your Product Hunt description outcome-first and within 500 characters?

**Category**: Asset Quality
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Under 500 characters; first sentence states user, pain, and outcome | 2 |
| B | Under 500 characters; outcome appears after the first sentence | 1 |
| C | Over 500 characters but still readable and specific | 0 |
| D | Vague, feature-heavy, or not finalized | 0 |

**Why This Matters**: Short, concrete descriptions match how users skim launch pages. Verbose or unclear descriptions weaken conversion from curiosity to trial.

### Q14. How strong is your proof layer across launch assets?

**Category**: Asset Quality
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Includes 2+ concrete proof points (usage metric, customer quote, integration logo) with permission | 2 |
| B | Includes 1 concrete proof point with permission | 1 |
| C | Uses only generic claims without evidence | 0 |
| D | No proof elements included | 0 |

**Why This Matters**: Credible proof reduces perceived risk for first-time visitors. Thin proof shifts attention to competitors with clearer validation.

### Q15. Is your call-to-action singular and unambiguous across page and assets?

**Category**: Asset Quality
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | One primary CTA repeated consistently across thumbnail, gallery, and page copy | 2 |
| B | One primary CTA plus one secondary action with clear hierarchy | 1 |
| C | Multiple competing CTAs in equal visual weight | 0 |
| D | No explicit CTA strategy | 0 |

**Why This Matters**: Clear CTAs convert attention into measurable actions. Competing asks fragment intent and lower activation rate.

### Q16. Have all launch assets been QA-tested on desktop and mobile in the last 72 hours?

**Category**: Asset Quality
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Full QA checklist completed on 2 desktop browsers and 2 mobile devices with fixes applied | 2 |
| B | QA completed on one desktop and one mobile device with minor fixes pending | 1 |
| C | Spot checks only; no documented QA checklist | 0 |
| D | No asset QA completed | 0 |

**Why This Matters**: Small display issues can erase the benefit of strong copy and design. Cross-device QA protects your conversion path during peak traffic windows.

## Category 3: Network Activation (Raw Max 20 | Weighted Max 20)

### Q17. What is the current status of your hunter plan?

**Category**: Network Activation
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Best-fit hunter identified, contacted, and confirmed participation date | 3 |
| B | Best-fit hunter identified and contacted, response pending | 2 |
| C | Hunter shortlist exists but no outreach sent | 1 |
| D | No hunter research completed | 0 |

**Why This Matters**: A deliberate hunter plan can increase trust and discovery flow. No plan creates avoidable uncertainty in launch setup and social proof.

### Q18. How prepared is your personalized outreach pipeline?

**Category**: Network Activation
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 40+ personalized messages drafted with recipient-specific context fields filled | 3 |
| B | 20-39 personalized messages drafted with context filled | 2 |
| C | 10-19 messages drafted with partial personalization | 1 |
| D | Fewer than 10 drafted messages or generic copy only | 0 |

**Why This Matters**: Personalized asks generate higher response quality than mass blasts. Weak outreach prep often leads to delayed engagement spikes.

### Q19. Do you have a distributed 24-hour engagement schedule with owners?

**Category**: Network Activation
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Hour-by-hour plan covering all 24 hours with assigned owners and channels | 3 |
| B | Plan covers at least 16 hours with assigned owners | 2 |
| C | Plan covers fewer than 16 hours or lacks clear ownership | 1 |
| D | No written schedule; relying on ad hoc posting | 0 |

**Why This Matters**: Rankings respond to sustained engagement, not one short burst. Coverage gaps can cause momentum drops that are hard to recover from.

### Q20. How complete is your launch-day DM list?

**Category**: Network Activation
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | 75+ contacts segmented by relationship type, timezone, and outreach timing | 3 |
| B | 40-74 segmented contacts with timing notes | 2 |
| C | 15-39 contacts without full segmentation | 1 |
| D | Fewer than 15 contacts or no structured list | 0 |

**Why This Matters**: Segmentation helps you time requests when people are most likely to respond. Unstructured outreach leads to poor timing and missed support windows.

### Q21. How established are you in communities you plan to activate?

**Category**: Network Activation
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Active in 3+ relevant communities with at least 5 helpful posts each in last 30 days | 2 |
| B | Active in 2 relevant communities with recent contribution history | 1 |
| C | Recently joined communities with minimal contribution history | 0 |
| D | No relevant community presence | 0 |

**Why This Matters**: Community trust determines whether launch posts are welcomed or ignored. Low trust reduces both visibility and meaningful conversation.

### Q22. How strong is your response coverage team for launch day?

**Category**: Network Activation
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | At least 2 responders plus founder, with shift coverage and escalation rules | 2 |
| B | Founder plus 1 responder with partial shift plan | 1 |
| C | Founder only with no break coverage | 0 |
| D | No response ownership defined | 0 |

**Why This Matters**: Fast replies sustain comment velocity and improve perceived reliability. Single-person coverage can create avoidable response lag during traffic peaks.

### Q23. Have you prepared a response bank for predictable launch questions?

**Category**: Network Activation
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | 20+ pre-drafted responses for pricing, onboarding, integrations, and roadmap questions | 2 |
| B | 10-19 pre-drafted responses covering core objections | 1 |
| C | Fewer than 10 responses drafted | 0 |
| D | No response bank prepared | 0 |

**Why This Matters**: Prepared responses improve speed and consistency under pressure. Without them, comment quality can drop when fatigue increases.

### Q24. Is there a launch command structure for decisions and escalation?

**Category**: Network Activation
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Written decision owner, fallback owner, and escalation triggers documented | 2 |
| B | Decision owner documented but no fallback owner | 1 |
| C | Informal verbal plan only | 0 |
| D | No decision structure defined | 0 |

**Why This Matters**: Clear ownership prevents decision stalls during ranking swings. Ambiguity burns critical minutes when timing matters most.

## Category 4: Timing & Positioning (Raw Max 20 | Weighted Max 20)

### Q25. How thoroughly have you reviewed competitive launch density for your target date?

**Category**: Timing & Positioning
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Reviewed previous 6 weeks of comparable categories and selected date based on documented density | 3 |
| B | Reviewed previous 3 weeks and avoided known crowded days | 2 |
| C | Reviewed only current week at a high level | 1 |
| D | No calendar analysis completed | 0 |

**Why This Matters**: Crowded days can suppress visibility even for strong products. Date selection should be a deliberate strategic choice, not a guess.

### Q26. Have you validated that your Product Hunt category choice matches buyer intent?

**Category**: Timing & Positioning
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Category tested with 10+ target users and benchmarked against top products in that category | 3 |
| B | Category benchmarked against top products but no user test | 2 |
| C | Category selected by intuition only | 1 |
| D | Category undecided or mismatched to product use case | 0 |

**Why This Matters**: Correct category placement puts you in front of the right evaluators. Misalignment brings traffic that rarely converts.

### Q27. How well do you understand your primary competitor's Product Hunt playbook?

**Category**: Timing & Positioning
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | Analyzed 3 competitor launches: assets, timing, comments, and engagement patterns | 3 |
| B | Analyzed 1-2 competitor launches with notes | 2 |
| C | Reviewed competitor pages briefly without structured notes | 1 |
| D | No competitor launch analysis | 0 |

**Why This Matters**: Competitor intelligence helps you avoid predictable mistakes and differentiate your message. Without it, your page can look interchangeable.

### Q28. Can you answer "why should this community care today" in one concrete sentence?

**Category**: Timing & Positioning
**Points Available**: 3

| Option | Answer | Points |
|--------|--------|--------|
| A | One-sentence why-now statement tested with 10+ target users and refined | 3 |
| B | One-sentence why-now statement tested with 5-9 users | 2 |
| C | Draft statement exists but not tested | 1 |
| D | No clear why-now positioning | 0 |

**Why This Matters**: Timely relevance increases comments and sharing behavior. Weak timing logic makes the launch feel optional and easy to ignore.

### Q29. How strong is your launch-day timing logic across timezone and audience behavior?

**Category**: Timing & Positioning
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Launch day selected with timezone heatmap and audience availability data | 2 |
| B | Day selected using prior campaign data but limited timezone modeling | 1 |
| C | Day selected for team convenience only | 0 |
| D | Launch time not finalized | 0 |

**Why This Matters**: Timing affects who sees your launch in the highest-leverage windows. Data-backed scheduling improves early interaction density.

### Q30. Do you have a contingency launch-day plan if competition is heavier than expected?

**Category**: Timing & Positioning
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Written contingency plan with alternate channel pushes and message variants | 2 |
| B | Partial contingency notes covering one alternate push window | 1 |
| C | General idea only; no written plan | 0 |
| D | No contingency plan | 0 |

**Why This Matters**: Conditions can shift quickly once the day starts. Contingency planning protects momentum when the board is unexpectedly competitive.

### Q31. How clearly is your product positioned against alternatives users already know?

**Category**: Timing & Positioning
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Positioning statement names target user, core alternative, and concrete differentiator | 2 |
| B | Positioning names user and differentiator, but no explicit alternative | 1 |
| C | Positioning is feature list only | 0 |
| D | No positioning statement written | 0 |

**Why This Matters**: Clear comparative framing reduces decision friction for new visitors. Missing comparison context makes evaluation slower and weaker.

### Q32. Is your launch offer strategy aligned with Product Hunt intent and urgency?

**Category**: Timing & Positioning
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Offer includes PH-specific value, clear expiry, and terms validated across checkout | 2 |
| B | Offer includes PH-specific value but incomplete expiry or terms clarity | 1 |
| C | Generic discount not tailored to PH audience | 0 |
| D | No launch offer strategy prepared | 0 |

**Why This Matters**: Strong offer design can convert curiosity into activation quickly. Poorly structured offers create confusion and lost conversions.

## Category 5: Retention Infrastructure (Raw Max 15 | Weighted Max 15)

### Q33. What is your measured time-to-value for a new user from signup to first meaningful outcome?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Median time-to-value under 60 seconds across at least 25 recent test users | 2 |
| B | Median time-to-value 61-120 seconds across at least 15 test users | 1 |
| C | Time-to-value over 120 seconds or tested with fewer than 15 users | 0 |
| D | No measured time-to-value baseline | 0 |

**Why This Matters**: Product Hunt traffic is high-intent but impatient. Faster first value directly improves trial activation and reduces bounce.

### Q34. Is your post-launch email lifecycle prepared for the first 7 days?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | 4+ emails scheduled (welcome, activation, objection handling, win-back) with tracking links | 2 |
| B | 2-3 emails scheduled with basic tracking | 1 |
| C | One welcome email only | 0 |
| D | No post-launch sequence prepared | 0 |

**Why This Matters**: Follow-up communication turns one-day attention into ongoing usage. No sequence often means low day-2 retention.

### Q35. Is a Product Hunt-exclusive offer code ready and fully tested?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Exclusive code created, tested in checkout, and expiry configured correctly | 2 |
| B | Code created and partially tested, with one unresolved edge case | 1 |
| C | Code drafted but not tested end-to-end | 0 |
| D | No exclusive offer code prepared | 0 |

**Why This Matters**: A launch-specific offer improves conversion clarity and tracking. Untested codes create trust damage during peak interest.

### Q36. How recently was the entire signup or checkout flow tested end-to-end?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Full flow tested in last 48 hours on desktop and mobile, including payment and confirmation | 2 |
| B | Full flow tested in last 7 days on one platform only | 1 |
| C | Partial flow testing only (missing payment or confirmation) | 0 |
| D | No recent end-to-end test | 0 |

**Why This Matters**: Hidden funnel breaks waste launch-day demand. Recency of QA is critical because small changes can introduce silent failures.

### Q37. Is live support coverage in place for onboarding blockers during launch day?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Live support channel staffed for at least 12 hours with SLA under 15 minutes | 2 |
| B | Live support staffed for 6-11 hours with SLA under 60 minutes | 1 |
| C | Async support only with response time over 60 minutes | 0 |
| D | No support coverage plan | 0 |

**Why This Matters**: Fast support saves conversions that would otherwise drop off. Slow response times increase churn risk from first-session friction.

### Q38. Do you have event tracking for the key activation and conversion steps?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | Tracking events live for signup, activation milestone, trial start, and paid conversion | 2 |
| B | Tracking events live for signup and activation only | 1 |
| C | Pageview-only analytics without funnel events | 0 |
| D | No reliable analytics instrumentation | 0 |

**Why This Matters**: Without event tracking, you cannot separate traffic problems from product problems. Measurement enables fast correction while the launch is still active.

### Q39. Is your user feedback capture loop ready for launch-day learning?

**Category**: Retention Infrastructure
**Points Available**: 2

| Option | Answer | Points |
|--------|--------|--------|
| A | In-app feedback prompt plus tagged inbox workflow and daily triage owner | 2 |
| B | Feedback form exists with manual review process | 1 |
| C | Ad hoc feedback collection in scattered channels | 0 |
| D | No defined feedback capture method | 0 |

**Why This Matters**: Rapid feedback routing helps you resolve blockers while attention is high. Unstructured feedback gets lost and delays fixes.

### Q40. Do you have a specific 7-day retention experiment planned for launch cohorts?

**Category**: Retention Infrastructure
**Points Available**: 1

| Option | Answer | Points |
|--------|--------|--------|
| A | One written experiment with success metric, owner, and ship date within 7 days | 1 |
| B | Experiment idea documented but no owner or deadline | 0 |
| C | General intent to "improve retention" without test design | 0 |
| D | No retention experiment planned | 0 |

**Why This Matters**: Launch day is the start of compounding, not the finish line. Teams with a short-cycle retention plan turn attention into durable revenue faster.

## Weighted Launch-to-Revenue Scoring

Use raw category totals from the 40 questions, then compute the weighted score below.

Weighted formula:
1. Audience Infrastructure: `(raw score / 25) x 25`
2. Asset Quality: `(raw score / 20) x 20`
3. Network Activation: `(raw score / 20) x 20`
4. Timing & Positioning: `(raw score / 20) x 20`
5. Retention Infrastructure: `(raw score / 15) x 15`

Rounded weighted total = your final score out of 100.

Why this weighting changed:
- Audience Infrastructure now carries the largest weight because launch-day ranking sensitivity is highest in the first hours, and early attention depth is the hardest lever to improvise late.
- The middle three categories remain balanced because page quality, activation execution, and positioning each influence conversion during different points in the same 24-hour window.
- Retention Infrastructure remains meaningful but lower because this scorecard is a pre-launch readiness diagnostic, not a post-launch lifecycle audit.

## Score Tier: Not Ready - Stop
**Range**: 0-49
**Headline**: You are exposed to multiple preventable leaks from traffic to revenue.

**What This Means**: Launching now can create activity without durable business outcomes. The most likely pattern is shallow engagement, weak activation, and unclear post-launch ownership.

**Your Highest-Risk Gap**: Your lowest-scoring category is likely below 40% of its raw maximum, which creates a measurable choke point in the first 6 hours (audience), first click-through session (assets), or first conversion window (activation/retention).

**Your Next Action**: Delay launch by 2-4 weeks and run a repair sprint on the single lowest category until it reaches at least 60% of raw max, with named owners and date-bound deliverables.

## Score Tier: Caution - Specific Gaps
**Range**: 50-69
**Headline**: Foundation is viable, but one or two weaknesses can block monetization.

**What This Means**: You may achieve visibility, but conversion quality remains fragile. This range often indicates one strong area and one structural gap that drags paid outcomes.

**Your Highest-Risk Gap**: One category is usually under 50% of raw max, which can negate gains from stronger categories and produce visible drop-off between Product Hunt traffic and activation metrics.

**Your Next Action**: Run a 7-10 day sprint on the lowest category plus one adjacent dependency, then re-score before launch and require both categories to clear 60% raw max.

## Score Tier: Ready - Execute the Plan
**Range**: 70-84
**Headline**: You are launch-capable with sufficient structure to convert attention.

**What This Means**: Core launch readiness is in place. Main upside now comes from disciplined execution and rapid correction when activation or paid conversion lags.

**Your Highest-Risk Gap**: Your lowest category is usually in the 55-70% range, which is strong enough to launch but still likely to leak performance if it is left unmanaged during the first 24 hours.

**Your Next Action**: Keep launch date, complete a 72-hour hardening pass for the lowest-scoring category, and pre-assign one contingency trigger tied to a specific metric threshold.

## Score Tier: Strong - Go for Top 3
**Range**: 85-100
**Headline**: You are positioned for high-quality launch execution and post-launch compounding.

**What This Means**: You have balanced readiness with strong retention infrastructure. The remaining risk is operational drift, not missing strategy.

**Your Highest-Risk Gap**: Even in this range, one category is usually the relative floor; if its score is under 80% of raw max, it can still cap upside and reduce Top 3 probability.

**Your Next Action**: Keep launch date and run a final-48-hour optimization pass on the single lowest category using prewritten owners, timing, and QA checklists.

**Top 3 Push**:
1. Finalize and schedule a 24-hour engagement roster with named owners and 2-hour response SLAs across comments and DMs.
2. Re-test onboarding plus checkout on desktop and mobile, then patch any blocker that adds more than 15 seconds to first value.
3. Send a personalized reminder wave to your top 30 confirmed supporters with exact launch time, comment angle, and share link.

## Revenue Readiness Output (Required)

After calculating your weighted score, complete this output before final launch approval.

1. **Revenue Risk Level**:
   - Red: weighted score below 60
   - Yellow: weighted score 60-79
   - Green: weighted score 80+
2. **Primary Constraint**: name one blocker in activation or paid conversion.
3. **Owner Assignment**: assign one owner to resolve the blocker with a deadline.
4. **Metric Target**: set one 7-day target for `activation_rate` or `paid_conversion_rate`.
5. **Protocol Choice**: select one rescue protocol from `playbook_v3.1.md` to preload.

If items 2-5 are incomplete, treat the launch as not approved.

## Understanding Your Score

### Audience Infrastructure
Audience Infrastructure measures your ability to create immediate, credible attention when your launch goes live. It captures list size and quality, committed first-hour supporters, Ship followers, and your existing relationship with the Product Hunt community. This category is weighted highest because launch ranking systems respond to early engagement intensity and consistency; without that base, even excellent assets can underperform. A high score here usually means you can trigger a meaningful first wave without begging for random attention, then sustain it through distributed channels. In practical terms, high-scoring teams can point to named people, known communities, and measured intent signals before launch day starts.

A low score does not mean your product is weak. It means your distribution layer is underbuilt for the timing and velocity that Product Hunt rewards. Launch-day consequence is often visible within the first few hours: slower comment cadence, weaker ranking recovery after dips, and lower confidence in outreach because the contact list was not prepared. The fix is concrete and measurable: build audience intentionally, increase quality interaction in PH communities, collect real commitment signals, and test launch-intent messaging before you schedule. If this category is below half of its maximum, delaying launch is usually less costly than learning the same lesson after a weak debut.

### Asset Quality
Asset Quality measures whether your launch page communicates value quickly enough for fast-scrolling visitors. It focuses on thumbnail clarity, tagline comprehension, first gallery image clarity, demo pacing, and concise outcome-first description quality. This category predicts click-through and conversion quality because users decide very quickly whether your product is relevant. A high score means your page passes comprehension tests with target users and avoids common launch friction such as vague copy, overloaded visuals, and unclear calls to action. High-scoring teams have tested assets with real humans and can show that understanding happens in seconds, not minutes.

When this category is weak, the launch usually suffers from silent leakage. You may still get page visits, but fewer people become commenters, signups, or activated users because they cannot decode the value fast enough. The launch-day consequence is misleading metrics: traffic looks acceptable while deeper actions underperform. The remedy is not prettier design alone; it is clearer communication with proof and tighter QA. Run short comprehension tests, trim copy aggressively, push the aha moment earlier in video, and verify everything on the smallest screens first. Asset Quality is where small improvements often create outsized gains because every visitor touches these surfaces before deciding what to do next.

### Network Activation
Network Activation measures your ability to coordinate people and channels over the full launch day, not just the opening post. It includes hunter strategy, outreach personalization, DM segmentation, community readiness, response coverage, and clear decision ownership. This category predicts whether momentum compounds or fades after the first spike. High-scoring launches have a written schedule with owners, pre-drafted responses for common questions, and enough coverage to keep engagement quality high even when the founder is overloaded. In practice, strong activation plans create a stable rhythm of comments, shares, and follow-up interactions that protects ranking through midday and late-day volatility.

Low scores here often show up as an uneven launch graph: initial excitement, then long quiet periods, delayed replies, and avoidable confusion about who should do what. Even with good assets, weak activation can flatten your reach because there is no sustained system behind the launch. The corrective path is operational, not abstract. Build segmented contact lists, personalize asks, schedule channel touchpoints by timezone, assign owners for each block of the day, and establish escalation rules before launch. Treat this category like incident readiness: when the board moves quickly, clarity and speed matter more than perfect prose.

A practical benchmark is coverage density: if fewer than two owners are active across each 4-hour block, response latency usually increases and comment quality declines by late day. Another benchmark is personalization depth: if less than 70% of your outreach list has recipient-specific context, response rates usually flatten after the initial wave. Launch-day consequence is measurable: longer median reply times, fewer second-order shares, and lower conversion from comments to site visits. To raise this category quickly, lock one command channel, define a single decision owner with fallback, and run a 60-minute rehearsal that stress-tests DM sends, comment response speed, and escalation handoffs before launch day.

### Timing & Positioning
Timing & Positioning measures whether you are launching on the right day with a message that fits community priorities. It combines calendar analysis, category selection, competitor intelligence, why-now clarity, and contingency planning. This category predicts relevance and comparability: will visitors understand why this product matters now and differs from alternatives? High-scoring teams choose timing deliberately, can explain category fit with evidence, and have prepared responses for competitive pressure. They avoid launching into crowded windows and reduce mismatch between who sees the product and who benefits from it.

A weak score in this category often causes hidden friction even if distribution and assets are strong. You might attract the wrong audience, appear generic next to similar launches, or miss the best windows for your user base. Launch-day consequences include lower conversion from comparable traffic levels and faster ranking decay when stronger-positioned products compete. Improvements are measurable: analyze recent boards, benchmark competitor launches, test your one-sentence why-now statement with target users, and create at least one contingency play for heavy competition. Timing and positioning do not replace product quality, but they determine whether quality is interpreted quickly in a crowded context.

Use concrete thresholds to judge readiness. If your why-now statement cannot be repeated accurately by at least 8 of 10 target testers, positioning risk is still high. If category choice is based on intuition without competitor benchmarking from the last 6 weeks, traffic relevance risk is high. If you lack a contingency trigger for a crowded board, operational risk is high. These risks have direct launch-day impact: weaker CTR from feed impressions, lower comment intent quality, and reduced recovery when rankings move quickly. To improve this category, write a one-page timing brief with chosen date, rejected dates, competing launches in your window, and a fallback message pack you can deploy quickly.

### Retention Infrastructure
Retention Infrastructure measures whether your product and follow-up systems can capture long-term value from launch-day attention. It covers time-to-value, lifecycle email readiness, offer-code reliability, end-to-end flow testing, support coverage, event tracking, and short-cycle retention experimentation. This category predicts whether launch success translates into usage and revenue instead of a one-day spike. High-scoring teams can onboard users quickly, observe where drop-off happens, respond to blockers in real time, and run immediate improvements for the launch cohort. They treat launch day as acquisition plus activation, not acquisition alone.

Low scores here create the most expensive failure mode: strong visibility with weak business outcomes. You may celebrate ranking while missing trial activation, paid conversion, or day-7 retention targets. The launch-day consequence is often delayed, appearing in the week after launch when cohort quality becomes clear. The fix is tactical: tighten onboarding to first value in under a minute, test checkout and code flows close to launch, prepare a seven-day email lifecycle, instrument activation events, and assign owners for feedback triage.

Measure this category with operating metrics instead of assumptions. If median time-to-value is above 90 seconds for new users, first-session abandonment risk is high. If fewer than four lifecycle emails are scheduled with event-based triggers, day-2 to day-7 recovery is weak. If checkout and offer-code paths have not been tested end-to-end within 48 hours, conversion reliability is uncertain. These gaps are fixable before launch: run two full-device QA passes, define one activation KPI and one paid conversion KPI, and set daily cohort reviews for the first seven days with explicit owners. Retention is weighted lower than Audience Infrastructure in this pre-launch model, but it still determines whether launch attention produces measurable business gains after day one.
